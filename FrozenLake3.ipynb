{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестовое задание для SLabAI\n",
    "### Выполнил Эдуард Аюнц, eayunts@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На странице FrozenLake на OpenAI можно найти приведенный ниже код, в нем используется алгоритм Q Learning, использующий уравнение Беллмана для динамической оптимизации. Данное решение дает точность порядка 50-60%,  и при написании персептрона, я ориентировался именно на это алгоритм, с той лишь разницой, что вместо уравнения Беллмана  сеть будет сама подбирать оптимальные веса, которые для данной инициализации ожидаемых выигрышей при каждом состоянии для каждого действия выведут действительный ожидаемый выигрыш"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-25 19:20:23,288] Making new env: FrozenLake-v0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "env = gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score over time: 0.401\n"
     ]
    }
   ],
   "source": [
    "Q = np.zeros([env.observation_space.n,env.action_space.n])\n",
    "lr = .7\n",
    "y = .99\n",
    "num_episodes = 1000\n",
    "rList = []\n",
    "for i in range(num_episodes):\n",
    "    s = env.reset()\n",
    "    rAll = 0\n",
    "    d = False\n",
    "    j = 0\n",
    "    while j < 99:\n",
    "        j+=1\n",
    "        L = Q[s,:] + np.random.randn(1,env.action_space.n)*(1./(i+1))\n",
    "        a = np.argmax(L)\n",
    "        s1,r,d,_ = env.step(a)\n",
    "        Q[s,a] = Q[s,a] + lr*(r + y*np.max(Q[s1,:]) - Q[s,a]) #уравнение Беллмана, то же самое ожидается от персептрона.\n",
    "        rAll += r\n",
    "        s = s1\n",
    "        if d == True:\n",
    "            break\n",
    "    #jList.append(j)\n",
    "    rList.append(rAll)\n",
    "print(\"Score over time: \" +  str(sum(rList)/(num_episodes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь непосредственно моя реализация."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1627,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork:    \n",
    "    \n",
    "    def __init__(self, num_features, hidden_size, seed=None):\n",
    "        env = gym.make('FrozenLake-v0')\n",
    "        self.num_features = num_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.init_weights(seed)\n",
    "    \n",
    "    def init_weights(self, seed):\n",
    "        np.random.seed(seed)\n",
    "        self.W1 = np.abs(np.random.normal(size=(self.num_features, self.hidden_size), scale=0.1) )\n",
    "        self.b1 = np.abs(np.random.normal(size=self.hidden_size))\n",
    "        self.W2 = np.abs(np.random.normal(size=(self.hidden_size, 1), scale=0.1))\n",
    "        self.b2 = np.abs(np.random.normal(size=64)) # на выход подается массив из 64 элементов\n",
    "        #идея в том, чтоб подавать на вход и получать матрицу ожидаемых выигрышей, которая состоин из 16*4=64 элементов\n",
    "        #нумерация следующая - первые 4 элемента - ожидаемые выигрыше при каждом действии в начальной точке, следующая четверка - \n",
    "        #из состояние с индексом 1 и так далее.\n",
    "        #следовательно,на выходе должны получаться та же таблица но с верными ожидаемыми выигрышами.\n",
    "\n",
    "        \n",
    "    def relu(self, x): # в качестве функции активации будем использовать  ReLU\n",
    "        return np.maximum(x, 0)\n",
    "    \n",
    "    def relu_grad(self, x):\n",
    "        return np.where(x > 0, 1, 0)\n",
    "    \n",
    "    def loss_gradient(self, X, y, s):\n",
    "        hidden = np.dot(X, self.W1) + self.b1 #персептрон\n",
    "        activation = self.relu(hidden)\n",
    "        answer = np.dot(activation, self.W2) + self.b2\n",
    "        s,r,d,_= env.step(np.argmax(answer[s*4:s*4+4]+np.random.rand(4))) #добавляю случайный вектор чтоб обогатить сеть\n",
    "       \n",
    "        global p # число сыгранных игр\n",
    "        global q # число побед\n",
    "        global m # число шагов в каждой игре\n",
    "        global error #производная ошибки\n",
    "        global n_steps #массив с числом шагов\n",
    "        \n",
    "        if d == True and r ==0: #если проигрыш, то ошибка равна 1\n",
    "            s = env.reset()\n",
    "            error = 1\n",
    "            n_steps.append(m)\n",
    "            p+=1 #увеличиваем число игр\n",
    "            m=1\n",
    "        elif d == True and r ==1: #при выигрыше ошибка равняется 0\n",
    "            s = env.reset()\n",
    "            error = 0\n",
    "            q+=1 #увеличиваем число побед\n",
    "            n_steps.append(m) # записываем в список число шагов до конца игры, для статистики\n",
    "            m=1\n",
    "        else: \n",
    "            m+=1 #число проделанных шагов\n",
    "            error = 1-m/20 #если игра продолжается, то ошибка уменьшается с ростом числа проделанных шагов\n",
    "        \n",
    "        db2 = np.sum(error) #обратное распространение ошибки\n",
    "        dW2 = activation.T.dot(error)\n",
    "\n",
    "        dhidden = self.relu_grad(hidden) * error * self.W2.T\n",
    "        db1 = dhidden.mean(0)\n",
    "        dW1 = np.array([X.T]).T.dot(dhidden)\n",
    "\n",
    "        return dW1, db1, dW2, db2\n",
    "\n",
    "    def gradient_descent(self, X, y, learning_rate,s):\n",
    "        dW1, db1, dW2, db2 = self.loss_gradient(X, y,s) \n",
    "        self.W1 -= dW1 * learning_rate #обновляем параметры\n",
    "        self.b1 -= db1 * learning_rate\n",
    "        dW2=dW2 * learning_rate\n",
    "        for i in range(100): #100 так как сто нейроной в скрытом слое\n",
    "            self.W2[i][0]-=dW2[i]\n",
    "        self.b2 -= db2 * learning_rate\n",
    "        \n",
    "    def fit(self, X, y, epochs, learning_rate):\n",
    "        s = env.reset()\n",
    "        s,r,d,_ = env.step(int(np.random.choice(4, 1))) #первый шаг делаем случайно\n",
    "        for epoch in range(epochs):\n",
    "            self.gradient_descent(X, y, learning_rate/(epoch+1),s) #добавил learning decay, при каждой эпохе темп \n",
    "             #изменения параметром будет снижаться"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В тестах экспериментировал с числом скрытых слоев, однако наилучший результат получался при числе порядка 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1644,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.abs(np.random.uniform(size =(64))) # инициализиурем случайно распределение матрицы ожидаемых выигрышей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1645,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-01-25 20:47:30,074] Making new env: FrozenLake-v0\n"
     ]
    }
   ],
   "source": [
    "nn = NeuralNetwork(64, hidden_size=100, seed=41)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Тесты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С learning rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1647,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68 games played \n",
      " 0 victories \n",
      " 0.0  percent accuracy\n",
      "14.4 mean n of steps \n",
      "\n",
      "176 games played \n",
      " 17 victories \n",
      " 9.66  percent accuracy\n",
      "5.2 mean n of steps \n",
      "\n",
      "172 games played \n",
      " 14 victories \n",
      " 8.14  percent accuracy\n",
      "5.4 mean n of steps \n",
      "\n",
      "181 games played \n",
      " 9 victories \n",
      " 4.97  percent accuracy\n",
      "5.2 mean n of steps \n",
      "\n",
      "176 games played \n",
      " 7 victories \n",
      " 3.98  percent accuracy\n",
      "5.5 mean n of steps \n",
      "\n",
      "168 games played \n",
      " 10 victories \n",
      " 5.95  percent accuracy\n",
      "5.6 mean n of steps \n",
      "\n",
      "165 games played \n",
      " 11 victories \n",
      " 6.67  percent accuracy\n",
      "5.7 mean n of steps \n",
      "\n",
      "90 games played \n",
      " 0 victories \n",
      " 0.0  percent accuracy\n",
      "11.0 mean n of steps \n",
      "\n",
      "57 games played \n",
      " 0 victories \n",
      " 0.0  percent accuracy\n",
      "17.2 mean n of steps \n",
      "\n",
      "181 games played \n",
      " 12 victories \n",
      " 6.63  percent accuracy\n",
      "5.2 mean n of steps \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    p=0  #счетчики\n",
    "    q=0\n",
    "    m=1\n",
    "    n_steps=[]\n",
    "    error=1\n",
    "    nn.fit(X, 1, epochs=1000, learning_rate=0.1)\n",
    "    print(p, 'games played \\n', q, 'victories \\n', np.round(100*q/p,2), \" percent accuracy\" )\n",
    "    print(np.round(np.mean(n_steps),1), 'mean n of steps \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь попробуем learning rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1648,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190 games played \n",
      " 10 victories \n",
      " 5.26  percent accuracy\n",
      "5.0 mean n of steps \n",
      "\n",
      "69 games played \n",
      " 0 victories \n",
      " 0.0  percent accuracy\n",
      "14.1 mean n of steps \n",
      "\n",
      "183 games played \n",
      " 10 victories \n",
      " 5.46  percent accuracy\n",
      "5.2 mean n of steps \n",
      "\n",
      "78 games played \n",
      " 0 victories \n",
      " 0.0  percent accuracy\n",
      "12.8 mean n of steps \n",
      "\n",
      "183 games played \n",
      " 8 victories \n",
      " 4.37  percent accuracy\n",
      "5.2 mean n of steps \n",
      "\n",
      "60 games played \n",
      " 0 victories \n",
      " 0.0  percent accuracy\n",
      "16.0 mean n of steps \n",
      "\n",
      "172 games played \n",
      " 10 victories \n",
      " 5.81  percent accuracy\n",
      "5.5 mean n of steps \n",
      "\n",
      "184 games played \n",
      " 10 victories \n",
      " 5.43  percent accuracy\n",
      "5.1 mean n of steps \n",
      "\n",
      "188 games played \n",
      " 6 victories \n",
      " 3.19  percent accuracy\n",
      "5.1 mean n of steps \n",
      "\n",
      "167 games played \n",
      " 9 victories \n",
      " 5.39  percent accuracy\n",
      "5.6 mean n of steps \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    p=0  #счетчики\n",
    "    q=0\n",
    "    m=1\n",
    "    n_steps=[]\n",
    "    error=1\n",
    "    nn.fit(X, 1, epochs=1000, learning_rate=0.001)\n",
    "    print(p, 'games played \\n', q, 'victories \\n', np.round(100*q/p,2), \" percent accuracy\" )\n",
    "    print(np.round(np.mean(n_steps),1), 'mean n of steps \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из интересных наблюдений - чередование нулевых запусков итераций с теми, которы набирают 5-6% выигрышей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1654,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1679,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средняя точность: 2.08256179775\n",
      "Максимальная точность 10.9\n",
      "Средняя точность среди успешных запусков 4.80140625\n",
      "Успешными посчитал запуски с точностью выше 1%\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    p=0  #счетчики\n",
    "    q=0\n",
    "    m=1\n",
    "    n_steps=[]\n",
    "    error=1\n",
    "    nn.fit(X, 1, epochs=1000, learning_rate=0.001)\n",
    "    #print(p, 'games played \\n', q, 'victories \\n', np.round(100*q/p,2), \" percent accuracy\" )\n",
    "    #print(np.round(np.mean(n_steps),1), 'mean n of steps \\n')\n",
    "    y.append(np.round(100*q/p,2))\n",
    "print('Средняя точность:',np.mean(y))\n",
    "print('Максимальная точность',np.max(y))\n",
    "x=[]\n",
    "for i in range(len(y)):\n",
    "    if y[i]>1: x.append(y[i])\n",
    "print('Средняя точность среди успешных запусков', np.mean(x))\n",
    "print('Успешными посчитал запуски с точностью выше 1%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1408,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.0"
      ]
     },
     "execution_count": 1408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(x) #максимальная достигнутая точность в ходе все тестов - 12% "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом это есть достигнутый мной результат, максимальная точность - 12%,  к сожалению различные эксперименты не позволили мне повысить качество алгоритма, \n",
    "буду рад услышать фидбек и узнать допущенные ошибки."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
